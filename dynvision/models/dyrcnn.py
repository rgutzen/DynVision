"""
DyRCNN: A biologically-inspired recurrent convolutional neural network.

This model implements key features of the visual cortex:
- Hierarchical processing (V1 -> V2 -> V4 -> IT)
- Recurrent connections within areas
- Skip and feedback connections between areas
- Retinal preprocessing
- Traveling wave patterns
- Neural dynamics with time constants

References:
- Kar et al. (2019) "Evidence that recurrent circuits are critical to the ventral stream's execution of core object recognition behavior"
- Muller et al. (2018) "Cortical travelling waves: mechanisms and computational principles"
"""

import logging
from typing import Optional, Union, Dict, Any, List

import torch
import torch.nn as nn

from dynvision.model_components import (
    EulerStep,
    SupraLinearity,
    Retina,
    LightningBase,
    InputAdaption,
    RecurrentConnectedConv2d,
    SkipConnection,
    Feedback,
)
from dynvision.utils import alias_kwargs, str_to_bool

__all__ = ["DyRCNNx2", "DyRCNNx4"]

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def validate_biological_parameters(
    dt: float, tau: float, t_feedforward: float, t_recurrence: float
) -> None:
    """Validate parameters for biological plausibility."""
    if dt <= 0:
        raise ValueError("Time step must be positive")
    if tau <= 0:
        raise ValueError("Time constant must be positive")
    if t_feedforward < 0:
        raise ValueError("Feedforward delay cannot be negative")
    if t_recurrence < 0:
        raise ValueError("Recurrent delay cannot be negative")
    if t_recurrence > t_feedforward:
        raise ValueError("Recurrent delay cannot exceed feedforward delay")


class DyRCNN(LightningBase):
    """
    Base class for DyRCNN models implementing core biological features.

    The model implements:
    - Recurrent processing within areas
    - Dynamical systems evolution
    - Biological time constants
    - Optional retinal preprocessing

    Args:
        n_classes: Number of output classes
        input_dims: Input dimensions (timesteps, channels, height, width)
        dt: Integration time step (ms)
        tau: Neural time constant (ms)
        t_feedforward: Feedforward delay (ms)
        t_recurrence: Recurrent delay (ms)
        recurrence_type: Type of recurrent connections
        train_tau: Whether to learn time constants
        bias: Whether to use biases in convolutions
        max_weight_init: Maximum initial weight value
        supralinearity: Degree of supralinear activation
        input_adaption_weight: Weight for input adaptation
        skip: Whether to use skip connections
        feedback: Whether to use feedback connections
        feedforward_only: Whether to disable recurrence
        stability_check: Whether to check stability
    """

    @alias_kwargs(
        taugrad="train_tau",
        supralin="supralinearity",
        winit="max_weight_init",
        inadapt="input_adaption_weight",
        ffonly="feedforward_only",
    )
    def __init__(
        self,
        n_classes: int = 200,
        input_dims: tuple = (14, 3, 64, 64),  # (t, c, y, x)
        dt: float = 2,  # ms
        tau: float = 8,  # ms
        t_feedforward: float = 10,  # ms
        t_recurrence: float = 6,  # ms
        recurrence_type: str = "none",
        train_tau: bool = False,
        bias: bool = True,
        max_weight_init: float = 0.001,
        supralinearity: float = 1,
        input_adaption_weight: float = 0,
        use_retina: bool = False,
        skip: bool = False,
        feedback: bool = False,
        feedforward_only: bool = False,
        stability_check: bool = False,
        **kwargs: Any,
    ) -> None:
        super().__init__(
            n_classes=n_classes,
            input_dims=input_dims,
            dt=float(dt),
            tau=float(tau),
            t_feedforward=float(t_feedforward),
            t_recurrence=float(t_recurrence),
            recurrence_type=recurrence_type,
            train_tau=str_to_bool(train_tau),
            bias=str_to_bool(bias),
            max_weight_init=float(max_weight_init),
            supralinearity=float(supralinearity),
            input_adaption_weight=float(input_adaption_weight),
            use_retina=str_to_bool(use_retina),
            skip=str_to_bool(skip),
            feedback=str_to_bool(feedback),
            feedforward_only=str_to_bool(feedforward_only),
            stability_check=stability_check,
            **kwargs,
        )
        validate_biological_parameters(
            self.dt, self.tau, self.t_feedforward, self.t_recurrence
        )

        # Calculate delays in timesteps
        self.delay_ff = int(self.t_feedforward / self.dt)
        self.delay_rc = int(self.t_recurrence / self.dt)

    def setup(self, stage: Optional[str]) -> None:
        """Set up model for training or evaluation."""
        super().setup(stage)

    def _define_architecture(self) -> None:
        raise NotImplementedError("Define the model architecture!")

    def configure_optimizers(self):
        return super().configure_optimizers()


class DyRCNNx4(DyRCNN, LightningBase):
    """
    Four-layer DyRCNN implementing a biologically-inspired visual hierarchy.

    Architecture:
    - V1: Primary visual cortex (low-level features)
    - V2: Secondary visual cortex (intermediate features)
    - V4: Visual area 4 (complex features)
    - IT: Inferotemporal cortex (object recognition)

    Features:
    - Hierarchical processing
    - Recurrent connections
    - Skip connections (if enabled)
    - Feedback connections (if enabled)
    - Retinal preprocessing (if enabled)
    """

    def __init__(self, **kwargs: Any) -> None:
        super().__init__(**kwargs)
        self._define_architecture()

    def reset(self) -> None:
        """Reset model state."""
        self.V1.reset()
        self.tstep_V1.reset()
        self.V2.reset()
        self.tstep_V2.reset()
        self.V4.reset()
        self.tstep_V4.reset()
        self.IT.reset()
        self.tstep_IT.reset()
        if hasattr(self, "input_adaption") and hasattr(self.input_adaption, "reset"):
            self.input_adaption.reset()
        if hasattr(self, "retina") and hasattr(self.retina, "reset"):
            self.retina.reset()

    def _define_architecture(self) -> None:
        """Define the four-layer visual hierarchy."""
        self.layer_names = ["V1", "V2", "V4", "IT"]
        # define operations order within layer
        self.layer_operations = [
            "layer",  # apply (recurrent) convolutional layer
            "addext",  # add external input
            "addskip",  # add skip connection
            "addfeedback",  # add feedback connection
            "tstep",  # apply dynamical systems ode solver step
            "nonlin",  # apply nonlinearity
            "supralin",  # apply supralinearity
            "record",  # record activations in responses dict
            "delay",  # set and get delayed activations for next layer
            "pool",  # apply pooling
            "norm",  # apply normalization
        ]

        # Activation functions
        self.nonlin = nn.ReLU(inplace=False)
        if hasattr(self, "supralinearity") and float(self.supralinearity) != 1:
            self.supralin = SupraLinearity(
                n=float(self.supralinearity), requires_grad=False
            )

        # Initialize retina
        if self.use_retina:
            self.bottleneck_channels = 18
            self.retina = Retina(
                in_channels=self.n_channels,
                out_channels=self.bottleneck_channels,
                mid_channels=36,
                kernel_size=9,
                bias=self.bias,
                stability_check=self.stability_check,
            )

        # Common layer parameters
        layer_params = dict(
            bias=self.bias,
            recurrence_type=self.recurrence_type,
            dt=self.dt,
            tau=self.tau,
            history_length=self.t_feedforward,
            recurrence_delay=self.t_recurrence,
            max_weight_init=self.max_weight_init,
            parametrization=lambda x: x,
            feedforward_only=self.feedforward_only,
            stability_check=self.stability_check,
        )

        # Input adaptation
        if self.input_adaption_weight:
            self.input_adaption = InputAdaption(
                fixed_weight=self.input_adaption_weight
            )

        # V1 layer
        in_channels = self.retina.out_channels if self.use_retina else self.n_channels
        self.V1 = RecurrentConnectedConv2d(
            in_channels=in_channels,
            out_channels=36,
            kernel_size=3,
            stride=1,
            dim_y=self.dim_y,
            dim_x=self.dim_x,
            **layer_params,
        )
        self.tau_V1 = torch.nn.Parameter(
            torch.tensor(self.tau, dtype=float),
            requires_grad=self.train_tau,
        )
        self.tstep_V1 = EulerStep(dt=self.dt, tau=self.tau_V1)
        self.pool_V1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # V2
        self.V2 = RecurrentConnectedConv2d(
            in_channels=self.V1.out_channels,
            out_channels=64,
            kernel_size=3,
            stride=1,
            dim_y=self.V1.dim_y // self.V1.stride // self.pool_V1.stride,
            dim_x=self.V1.dim_x // self.V1.stride // self.pool_V1.stride,
            **layer_params,
        )
        self.tau_V2 = torch.nn.Parameter(
            torch.tensor(self.tau, dtype=float),
            requires_grad=self.train_tau,
        )
        self.tstep_V2 = EulerStep(dt=self.dt, tau=self.tau_V2)
        self.pool_V2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # V4
        self.V4 = RecurrentConnectedConv2d(
            in_channels=self.V2.out_channels,
            out_channels=121,
            kernel_size=3,
            stride=1,
            dim_y=self.V2.dim_y // self.V2.stride // self.pool_V2.stride,
            dim_x=self.V2.dim_x // self.V2.stride // self.pool_V2.stride,
            **layer_params,
        )
        if self.skip:
            self.addskip_V4 = SkipConnection(
                source=self.V1,
                auto_adapt=True,
            )
        if self.feedback:
            self.addfeedback_V1 = Feedback(
                source=self.V4,
                # in_channels=self.V4.out_channels,
                # out_channels=self.V1.in_channels,
                # scale_factor=self.V4.dim_y / self.V1.dim_y,
                auto_adapt=True,
            )
        self.tau_V4 = torch.nn.Parameter(
            torch.tensor(self.tau, dtype=float),
            requires_grad=self.train_tau,
        )
        self.tstep_V4 = EulerStep(dt=self.dt, tau=self.tau_V4)
        self.pool_V4 = nn.MaxPool2d(kernel_size=1, stride=1, padding=0)

        # IT
        self.IT = RecurrentConnectedConv2d(
            in_channels=self.V4.out_channels,
            out_channels=256,
            kernel_size=3,
            stride=2,
            dim_y=self.V4.dim_y // self.V4.stride // self.pool_V4.stride,
            dim_x=self.V4.dim_x // self.V4.stride // self.pool_V4.stride,
            **layer_params,
        )
        if self.skip:
            self.addskip_IT = SkipConnection(
                source=self.V2,
                auto_adapt=True,
            )
        if self.feedback:
            self.addfeedback_V2 = Feedback(
                source=self.IT,
                # in_channels=self.IT.out_channels,
                # out_channels=self.V2.in_channels,
                # scale_factor=self.IT.dim_y / self.V2.dim_y,
                auto_adapt=True,
            )
        self.tau_IT = torch.nn.Parameter(
            torch.tensor(self.tau, dtype=float),
            requires_grad=self.train_tau,
        )
        self.tstep_IT = EulerStep(dt=self.dt, tau=self.tau_IT)

        # Classifier
        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(self.IT.out_channels, self.n_classes),
        )

    def setup(self, stage: Optional[str]) -> None:
        if stage == "fit" and self.feedback:
            # run forward pass to init feedback connections
            for layer_name in self.layer_names:
                if hasattr(self, f"addfeedback_{layer_name}"):
                    getattr(self, f"addfeedback_{layer_name}").reset_transform()

            x = torch.randn((1, *self.input_dims), device=self.device)
            y = self.forward(x, store_responses=False)

            self.reset()

        super().setup(stage)

    def _init_parameters(self) -> None:
        super()._init_parameters()

        trunc_normal_params = dict(mean=0.0, std=0.004)

        for layer_name in self.layer_names:
            layer = getattr(self, layer_name)
            if hasattr(layer, "conv.weight") and not hasattr(
                layer, "conv.weight.original1"
            ):
                nn.init.trunc_normal_(layer.conv.weight, **trunc_normal_params)

        nn.init.trunc_normal_(self.classifier[-1].weight, **trunc_normal_params)
        nn.init.constant_(self.classifier[-1].bias, 0)


class DyRCNNx2(DyRCNN):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self._define_architecture()

    def reset(self):
        self.layer1.reset()
        self.tstep_layer1.reset()
        self.layer2.reset()
        self.tstep_layer2.reset()
        if hasattr(self, "input_adaption"):
            self.input_adaption.reset()

    def _define_architecture(self):
        self.layer_names = ["layer1", "layer2"]
        # define operations order within layer
        self.layer_operations = [
            "layer",  # apply (recurrent) convolutional layer
            "addext",  # add external input
            "addskip",  # add skip connection
            "addfeedback",  # add feedback connection
            "tstep",  # apply dynamical systems ode solver step
            "nonlin",  # apply nonlinearity
            "supralin",  # apply supralinearity
            "record",  # record activations in responses dict
            "delay",  # set and get delayed activations for next layer
            "pool",  # apply pooling
            "norm",  # apply normalization
        ]

        # Input adaption
        if self.input_adaption_weight:
            self.input_adaption = InputAdaption(
                fixed_weight=self.input_adaption_weight
            )

        if hasattr(self, "supralinearity") and float(self.supralinearity) != 1:
            self.supralin = SupraLinearity(
                n=float(self.supralinearity), requires_grad=False
            )

        # Define the convolutional layers
        layer_params = dict(
            bias=self.bias,
            recurrence_type=self.recurrence_type,
            dt=self.dt,
            tau=self.tau,
            history_length=self.t_feedforward,
            recurrence_delay=self.t_recurrence,
            parametrization=lambda x: x,  # nn.utils.parametrizations.weight_norm,
            device=self.device,
        )

        # Define the convolutional layers
        self.layer1 = RecurrentConnectedConv2d(
            in_channels=self.n_channels,
            out_channels=36,
            kernel_size=3,
            stride=1,
            dim_y=self.dim_y,
            dim_x=self.dim_x,
            **layer_params,
        )
        self.tstep_layer1 = EulerStep(dt=self.dt, tau=self.tau)
        self.nonlin_layer1 = nn.ReLU(inplace=False)
        self.pool_layer1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        self.layer2 = RecurrentConnectedConv2d(
            in_channels=self.layer1.out_channels,
            out_channels=64,
            kernel_size=3,
            stride=1,
            dim_y=self.layer1.dim_y // self.layer1.stride // self.pool_layer1.stride,
            dim_x=self.layer1.dim_x // self.layer1.stride // self.pool_layer1.stride,
            **layer_params,
        )
        self.tstep_layer2 = EulerStep(dt=self.dt, tau=self.tau)
        self.nonlin_layer2 = nn.ReLU(inplace=False)
        if self.feedback:
            self.addfeedback_layer1 = Feedback(source=self.layer2, autoadapt=True)

        self.classifier = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(self.layer2.out_channels, self.n_classes, device=self.device),
        )

    def setup(self, stage: Optional[str]) -> None:
        if stage == "fit" and self.feedback:
            # run forward pass to init feedback connections
            for layer_name in self.layer_names:
                if hasattr(self, f"addfeedback_{layer_name}"):
                    getattr(self, f"addfeedback_{layer_name}").setup_transform = True

            x = torch.randn((1, *self.input_dims), device=self.device)
            y = self.forward(x, store_responses=False)

            self.reset()

        super().setup(stage)

    def _init_parameters(self):
        super()._init_parameters()

        trunc_normal_params = dict(mean=0.0, std=0.004)

        for layer_name in self.layer_names:
            layer = getattr(self, layer_name)
            if hasattr(layer, "conv.weight") and not hasattr(
                layer, "conv.weight.original1"
            ):
                nn.init.trunc_normal_(layer.conv.weight, **trunc_normal_params)

        nn.init.trunc_normal_(self.classifier[-1].weight, **trunc_normal_params)
        nn.init.constant_(self.classifier[-1].bias, 0)


if __name__ == "__main__":
    # Test configuration
    input_shape = (20, 3, 64, 64)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"Testing on device: {device}")

    # Create model
    model = DyRCNNx4(
        input_dims=input_shape,
        n_classes=200,
        store_responses=True,
        tff=13,
        device=device,
    )
    model.setup("fit")

    # Test forward pass
    x = torch.randn(1, *input_shape, device=device)
    y = model(x)

    logger.info(f"Input shape: {x.shape}")
    logger.info(f"Output shape: {y.shape}")
    logger.info(f"Residual timesteps: {model.n_residual_timesteps}")

    # Test stability
    try:
        model(torch.full_like(x, float("inf")))
        assert False, "Should raise stability error"
    except ValueError:
        logger.info("Stability check passed")

    logger.info("All tests passed!")
