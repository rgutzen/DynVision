# Workflow parameters - running rule all
model_name:
  # - AlexNet
  # - CorNetRT
  # - TwoLayerCNN
  # - FourLayerCNN
  - DyRCNNx4
  # - CordsNet
  # - ResNet20
  # - ResNet18
  # - ResNet1202
  # - ResNet44
seed: "0015"
model_args:
  # tsteps: 20
  # tau: [5, 8, 11, 14, 17]
  # trc: [5, 10, 15, 20]
  # tff: 25
  # dt: 2
  # tau: 8
  # trc: 6
  # tff: 10
  rctype: 'full'
  # rctype: ['self', 'full', 'pointdepthwise', 'depthpointwise', 'local', 'localdepthwise']
  # rctype: ['local'] # ['localdepthwise'] 
  skip: 'true'
  feedback: 'true'
  # supralin: [1.000000001, 1.0000001, 1.00001, 1.001, 1.1]
  # taugrad: 'true'
  # lossrt: 20
  # inadapt: 0.9
  # inadapt: [0.3, 0.6, 0.9]

init_with_pretrained: False

# data_name: imagenet
# data_name: tinyimagenet
data_name: cifar100
# data_name: cifar10
# data_name: mnist
# data_name: snakenet

# data_group: "snakes"  # imagenet
# data_group: "imagenette"  # imagenet
# data_group: "89"  # mnist
# data_group: "mollusks"  # tinyimagenet
data_group: "invertebrates"  # cifar100
# data_group: "all"

experiment: 
  - response
  - responseffonly
  - duration
  # - stability
  - contrast
  - interval
  # - noiseadaption
  # - spatialsplit

# Training parameters
loss: 
  - CrossEntropyLoss  # CrossEntropySpatialCorrelationLoss 
  # - EnergyLoss

optimizer: Adam
learning_rate: 0.001
epochs: 200
batch_size: 512
accumulate_grad_batches: 1
check_val_every_n_epoch: 10

# Trainer configuration
trainer:
  # Gradient clipping settings
  automatic_optimization: True
  clip_gradients: True
  gradient_clip_algorithm: "norm"  # "norm" or "value"
  gradient_clip_val: 1.0  # global clip value

  # Learning rate scaling settings
  lr_scaling:
    enabled: true  # whether to scale learning rate with batch size
    ref_batch_size: 64  # reference batch size for scaling
    threshold_factor: 8  # maximum scaling threshold

  # Hardware and precision settings
  # precision: "32"  # Changed to full precision for debugging feedback stability
  accelerator: "auto"
  devices: "auto"
  strategy: "auto"
  deterministic: false  # Consider setting to true if still unstable