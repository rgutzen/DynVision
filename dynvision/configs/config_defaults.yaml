# Namespace
classifier_name: classifier

# Model
retain_graph: False  # retain the computational graph for repeated backprop paths
status: trained
n_timesteps: 20
dt: 2  # ms
tau: 8  # ms
t_recurrence: 6  # ms
t_feedforward: 10  # ms
recurrence_influence: 'additive'  # 'additive' or 'multiplicative'
init_with_pretrained: False
store_train_responses: 0 # n_samples
store_val_responses: 0  # n_samples (currently no in use)
store_test_responses: 100  # n_samples
store_responses_on_cpu: True

# Data
data_name: mnist
data_group: all
data_timesteps: 1
prefetch_factor: 1

# Training run
seed: "0000"
train_ratio: 0.8
epochs: 200
batch_size: 257
check_val_every_n_epoch: 10
log_every_n_steps: 20
accumulate_grad_batches: 4
precision: "bf16-mixed"
profiler: None
benchmark: True
enable_progress_bar: False
# tbptt_length: None
limit_val_batches: 0.25
reload_dataloaders_every_n_epochs: 0
automatic_optimization: True
clip_gradients: False
gradient_clip_algorithm: "norm"  # "norm" or "value"
gradient_clip_val: 1.0  # global clip value
deterministic: False  # Consider setting to true if still unstable
use_distributed: False

# Test run
logger: False

# Loss
loss: 
  - CrossEntropyLoss
loss_configs:
  CrossEntropyLoss:
    weight: 1
    ignore_index: -1
  EnergyLoss:
    weight: 100
loss_reaction_time: 0  # ms (+ residual time)
non_label_index: -1

# Optimizer
optimizer: Adam
optimizer_kwargs:
  weight_decay: 0.0005
  fused: False
optimizer_configs:
  monitor: train_loss

# Learning rate parameter groups
lr_parameter_groups:
  regular:
    lr_factor: 1.0
  recurrence:
    lr_factor: 0.2
  feedback:
    lr_factor: 0.5

# Learning rate
learning_rate: 0.0002
scheduler: CosineAnnealingLR
scheduler_kwargs:
  T_max: 250
scheduler_configs:
  interval: epoch
  frequency: 1
  monitor: train_loss
  name: lr_scheduled
lr_scaling:
  enabled: False  # whether to scale learning rate with batch size
  ref_batch_size: 64  # reference batch size for scaling
  threshold_factor: 8  # maximum scaling threshold

# Trainer configuration
# Gradient clipping settings

# System
log_level: info
use_executor: False
verbose: True